---
title: "技術情報収集を自動化したら、キャッチアップ疲れがなくなった（n8n）"
emoji: "📰"
type: "tech"
topics: ["n8n", "supabase", "railway", "openai", "rss"]
published: false
---

## はじめに

今更ながら [n8n](https://n8n.io/) の環境を構築してみて、手始めに技術系の情報収集を自動化するシステムを作ったので、その備忘録です。

私は普段 Web 系の開発をしていて、技術系のアップデートやブログ、最近では AI 関連のニュースをサイトや X などでキャッチアップしています。
今までそういったキャッチアップは RSS Reader である [Inoreader](https://www.inoreader.com/ja/) を使って様々なサイトの RSS を追っていたのですが、気づくと未読が数百件になっていて、正直キャッチアップ疲れを起こしていました。

そこで、せっかく n8n の環境を作ってみたので、溢れている技術情報を AI に自分の興味に合わせて選別・要約してもらい、定期的に Discord に送ってもらうようにしました。
このシステムを作ったことで、今まで頑張って追っていた情報が定期的に AI がキュレーションしてプッシュされてくるようになり、情報収集が楽になりました。

### 例：フロントエンドに関するトピック

以下のような投稿が6数時間ごとに Discord に届くように設定

![Discord の配信](/images/n8n-tech-news-collector/discord-post.png)

## システム概要

### やりたかったこと

- RSS フィードや X から記事・ポストを自動収集
  - 情報を正規化して DB に蓄積
- AI による分析・要約・カテゴリ分類（海外記事は翻訳も）
- 数時間ごとに Discord へダイジェストを投稿
  - プロンプトに応じて AI が記事を選別して要約

### 技術構成

| 役割               | 技術                                              |
|------------------|-------------------------------------------------|
| ワークフロー自動化        | n8n                                             |
| ホスティング           | Railway                                         |
| データベース           | Supabase（PostgreSQL）                            |
| 分析・要約・キュレーション | OpenAI API                                      |
| 開発支援             | Claude Desktop <br/> MCP（Supabase MCP, n8n MCP） |

![architecture.png](/images/n8n-tech-news-collector/architecture.png)

## アーキテクチャ設計

### Input / Output を分離する設計

定期実行による AI キュレーションと拡張性を考慮して、収集（Input）と配信（Output）を分離しています。

- Input フロー
  - RSS 収集 → AI 分析 → DB 保存
  - 今後 X（Twitter）やスクレイピングからの収集も追加予定
- Output フロー
  - DB から取得 → AI で要約生成 → Discord 配信
  - 今後 Web サイトへの掲載なども追加予定

### ワークフロー構成

| ワークフロー名                                    | 役割 |
|--------------------------------------------|------|
| Tech News Collector - Fetch RSS            | RSS 取得・サブワークフロー呼び出し |
| Tech News Collector - Process RSS Articles | 記事処理・AI 分析・DB 保存 |
| Tech News Collector - Send (*)             | カテゴリ別に Discord へ配信 |

## Tech News Collector - Fetch RSS

まずは、記事を収集する Input の処理です。  
RSS フィードを取得して各記事を処理するサブワークフローに渡すメインワークフローです。（30分ごとに実行）

![fetch-rss.png](/images/n8n-tech-news-collector/fetch-rss.png)

### ポイント

- Limit Articles
  - 記事数が膨大な RSS があるため、取得数を制限しています
  - 初回実行時に太古の記事まで大量に読み込んでひたすらお金を垂れ流してしまった...
- Add Feed Info
  - サブワークフローにフィードソース情報を渡しています
  - n8n の Split In Batches（ループ処理）はネストできない制約があるようです（この制約を知らず数時間ハマった...）
  - 今回は RSS フィードのループ → 記事のループ、という二重ループが必要だったため、記事処理をサブワークフローに切り出してこの問題を回避しています。
- Set Start Time
  - 完了通知時に「今回追加された記事」を取得するために、ワークフロー開始時刻を記録しています
- エラーハンドリング
  - RSS 取得失敗時は通知してスキップし、次のフィードへ継続するようにしています

## Tech News Collector - Process RSS Articles

RSS で取得した記事を1件ずつ処理し、AI で分析して DB に保存するサブワークフローです。

![process-rss-articles.png](/images/n8n-tech-news-collector/process-rss-articles.png)

### ポイント

- guid で重複スキップ
  - RSS の guid を使って、同じ記事を二重登録しないようにしています
- フィードの内容を正規化 
  - サイトごとにフィードのプロパティがばらばらなので `Normalize RSS Data` で必ず同じ構造になるように変換
  - guid もなければ、ここで生成しています
- AI 分析
  - タイトル翻訳、要約生成、キーワード抽出、カテゴリ分類を一括処理しています
- テストモード
  - サブワークフロー化したことで、単体テスト実行時にデータを渡せないため追加
  - 実行時にデータが渡ってきていなかったら、RSS をひとつだけワークフローに渡すようにしています

### AI 分析の内容

`Analyze` ノードでは OpenAI API を使って、以下の情報を抽出・生成しています。

| 項目 | 内容 |
|------|------|
| タイトル | 日本語タイトル（英語記事は翻訳） |
| カテゴリ | 記事の分類（AI/ML、フロントエンド、ビジネスなど） |
| キーワード | 記事の重要なキーワード（3〜5個） |
| 要約 | 日本語での要約（200〜300字） |
| 元言語 | 記事の元の言語（ja / en） |

プロンプトでは、要約のスタイル（ですます調、メタ表現禁止など）やカテゴリの選択ルールを細かく指定しています。

![analyze-node.png](/images/n8n-tech-news-collector/analyze-node.png)

:::details Analyze ノードの System Message
あなたは技術記事を分析するアシスタントです。
渡された記事情報を分析し、指定されたJSON形式で結果を返してください。

## 分析タスク

1. title（タイトル）: 日本語のタイトル（英語の場合は翻訳）
2. category（カテゴリ）: 記事の内容に該当するカテゴリを1〜3個選択（配列で返す）
3. keywords（キーワード）: 記事の重要なキーワードを3〜5個抽出
4. summary（要約）: 記事の要点を日本語で要約
5. original_language（元言語）: 記事の元の言語を判定

## タイトルのルール

- 日本語記事: 元のタイトルをそのまま使用
- 英語記事: 日本語に翻訳（固有名詞・サービス名・技術用語は英語のまま維持）

## カテゴリ一覧（必ずこの中から選択）

- ai_ml: AI・機械学習・LLM関連
- frontend: フロントエンド（React, Vue, CSS等）
- backend: バックエンド（API, サーバーサイド等）
- infrastructure: インフラ・クラウド（AWS, GCP, Azure, Kubernetes等）
- security: セキュリティ・脆弱性
- devops: DevOps・CI/CD・自動化
- mobile: モバイルアプリ開発（iOS, Android, Flutter等）
- database: データベース（SQL, NoSQL等）
- programming: プログラミング言語・開発手法一般
- architecture: システム設計・ソフトウェアアーキテクチャ・設計パターン
- technology: ハードウェア・ガジェット・新技術（CPU, GPU, デバイス, 量子コンピュータ等）
- ui_ux: UI/UXデザイン・ユーザビリティ・アクセシビリティ
- design: グラフィックデザイン・デザインツール・デザインシステム
- business: テック業界ニュース・企業動向・買収等
- general: 複数分野にまたがる技術トピック・総合的な技術情報
- tech_blog: 個人の技術ブログ記事（下記参照）
- other: 上記に該当しないもの

## カテゴリ選択のルール

- 最も関連性の高いカテゴリを1〜3個選択する
- 1つで十分な場合は1つだけでよい
- 最大3個まで（4個以上は選択しない）
- 優先度の高い順に並べる

## tech_blog カテゴリの判定基準

tech_blog は「個人（エンジニア・開発者）が書いた技術記事」を指します。

tech_blog に該当するもの：
- 個人の体験談・経験共有（「〜してみた」「〜を導入した話」「〜で苦労した」）
- 技術ポエム・エッセイ・考察
- 個人の学習記録・備忘録
- 「やってみた」「作ってみた」「試してみた」系の記事
- 開発者個人の意見・主張が中心の記事
- Zenn、Qiita、dev.to、note、はてなブログなどの個人投稿記事
- 企業の技術ブログでも、個人名が明記された体験談・知見共有

tech_blog に該当しないもの：
- ニュースメディアの報道記事（TechCrunch、CNET、Engadget、ITmedia、GIGAZINE等）
- プレスリリース・公式発表
- 製品・サービスの公式ドキュメント
- 記者・ライターによる取材記事
- 客観的な事実報道が中心の記事

## 言語一覧（必ずこの中から選択）

- ja: 日本語
- en: 英語

## 要約のルール

- **本文（content）が空または存在しない場合は、要約を生成せず空文字（""）を返す**
- 本文がある場合のみ、以下のルールに従って要約を生成する：
    - 日本語で200〜300字で作成
    - 追加の推測や脚色は禁止（記事に書かれている事実のみ）
    - 重要な数値・比較・結論は必ず残す
    - 一段落で出力（箇条書き禁止）
    - 具体的なソースコードやコマンドは記載禁止
    - ですます調で統一（例：〜いる→〜います、〜だ→〜です）
    - 「この記事では」「この記事は」「本記事では」などのメタ表現で始めない
    - 主語（企業名、サービス名、技術名など）から直接書き始める

## キーワードのルール

- 配列内の各キーワードは必ずダブルクオート（"）で囲むこと
- 日本語のキーワードも必ずダブルクオートで囲むこと
- 本文が空の場合は、タイトルから推測できるキーワードのみを抽出する
- 例: ["Claude Code", "CLAUDE.md", "コンテキスト", "プロジェクトルール"]

## 出力形式

以下のJSON形式のみを出力してください。説明文やマークダウンの装飾は不要です。
すべての文字列値は必ずダブルクオートで囲んでください。

{
"title": "日本語タイトル",
"category": ["カテゴリ1", "カテゴリ2"],
"keywords": ["キーワード1", "キーワード2", "キーワード3"],
"summary": "日本語での要約文（本文が空の場合は空文字）",
"original_language": "言語コード"
}
:::

### DB スキーマ

DB のスキーマは現状、購読する RSS を登録するものと、取得した記事を正規化して保存するだけになっています。

![db-schema.png](/images/n8n-tech-news-collector/db-schema.png)

## Tech News Collector - Send (*)

ここからは Output の処理です。  
`Send (*)` は DB から記事を取得し、AI でダイジェストを生成して Discord に配信するワークフローです。  
`notice-frontend` のようにチャンネルを分けたかったので、カテゴリごとにワークフローを分けています。

![send-ai-ml.png](/images/n8n-tech-news-collector/send-ai-ml.png)

### ポイント

- カテゴリ別にワークフローを分離
  - AI/ML、フロントエンド、ビジネスなど、関心に合わせて配信先を分けています
- AI によるダイジェスト生成
  - 溜まった記事からトレンド要約とおすすめ記事を生成しています
- ユーザーメッセージで抽出条件を調整
  - プロンプトを変えるだけで配信内容をカスタマイズできるようにしています
  - 後々はこのプロンプトを動的に変えられるようにして、ユーザーごとにキュレーション内容を変更できるようにしたい

![user-prompt.png](/images/n8n-tech-news-collector/user-prompt.png)

### 配信メッセージの例

AI が生成するメッセージは以下のような形式です。

![discord-post.png](/images/n8n-tech-news-collector/discord-post.png)

定期投稿のため、いつ投稿されたのかをわかりやすくしたり、トピックの要約やそれに関するおすすめの記事を数個だけ限定して提示したりなど、情報収集の負担を減らすようにしています。
プロンプトやモデルを調整すれば、さらに精度が上がりそうなので要調整です。

## 開発プロセス

今回の開発では、プラットフォームと MCP の力を借りて、スムーズに開発できました。

### n8n の環境構築

[Railway](https://railway.app/) のテンプレートがあったので、数クリックで n8n の環境を構築できました。
テンプレートでは、内部 DB や Redis、Worker 用のインスタンスなどが自動的に構築されて、すぐにワークフローの開発を始められました。

![railway.png](/images/n8n-tech-news-collector/railway.png)

### Claude Desktop + MCP の活用

Claude Desktop + MCP を活用して、設計・DB 構築・レビューをできるだけ効率化しました。

- **Supabase MCP**：テーブル作成、マイグレーション適用、データ確認
- **n8n MCP**：ワークフローの取得・レビュー、ピンポイント修正

特に Supabase MCP は便利で、ほぼ Supabase の GUI は触らずテーブルの作成やデータの操作ができました。

### n8n MCP の現状

n8n の MCP は、Supabase のようにいい感じにやってくれることを期待しましたが、現状はまだ発展途上でした。  
特にワークフローを 0→1 で作成するのはまだ難しそうです（うまいやり方があったら教えてください）。

ですが、以下の用途には十分使えそうでした。

- 設計段階での壁打ち
- 既存ワークフローの構造を把握する
- ピンポイントでのノードの修正

## おわりに

今後は収集ソースの追加（スクレイピング、X など）や、配信先の拡張（Web サイトなど）をやっていきたいと思います。  
また、プロンプトの調整などもまだまだできそうなので、少しずつ修正していけたらなと思います。

n8n のようなノーコードツールと AI や MCP を組み合わせると、ここまで手軽に自動化できるシステムを作れる時代になってきてとても嬉しいですね。  
それと同時にエンジニアとしての立場が危うくなってきていて怖い今日このごろです。

みなさんもぜひご興味あれば n8n でなにか作ってみてください！

おわり。

## 参考

- [n8n](https://n8n.io/)
- [n8n 公式ドキュメント](https://docs.n8n.io/)
- [Supabase 公式ドキュメント](https://supabase.com/docs)
- [Railway](https://railway.app/)
- [Inoreader](https://www.inoreader.com/ja/)
